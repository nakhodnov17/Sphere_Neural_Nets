{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uppercase local vars:\n",
      "\tBATCH_SIZE: 50\n",
      "\tCRITIC_ITERS: 5\n",
      "\tDIM: 64\n",
      "\tF: <module 'torch.nn.functional' from '/home/m.nakhodnov/anaconda3/envs/py2.7.14/lib/python2.7/site-packages/torch/nn/functional.pyc'>\n",
      "\tITERS: 200000\n",
      "\tLAMBDA: 10\n",
      "\tOUTPUT_DIM: 784\n",
      "Generator(\n",
      "  (block1): Sequential(\n",
      "    (0): ConvTranspose2d(256, 128, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): ReLU(inplace)\n",
      "  )\n",
      "  (block2): Sequential(\n",
      "    (0): ConvTranspose2d(128, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): ReLU(inplace)\n",
      "  )\n",
      "  (deconv_out): ConvTranspose2d(64, 1, kernel_size=(8, 8), stride=(2, 2))\n",
      "  (preprocess): Sequential(\n",
      "    (0): Linear(in_features=128, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace)\n",
      "  )\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Discriminator(\n",
      "  (main): Sequential(\n",
      "    (0): Conv2d(1, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Conv2d(64, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
      "    (3): ReLU(inplace)\n",
      "    (4): Conv2d(128, 256, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
      "    (5): ReLU(inplace)\n",
      "  )\n",
      "  (output): Linear(in_features=4096, out_features=1, bias=True)\n",
      ")\n",
      "iter 0\ttmp/mnist/wasserstein distance\t0.182501062751\ttmp/mnist/train gen cost\t0.232804551721\ttmp/mnist/time\t1.22622609138\ttmp/mnist/train disc cost\t8.7073841095\n",
      "iter 1\ttmp/mnist/wasserstein distance\t0.662254929543\ttmp/mnist/train gen cost\t0.70666795969\ttmp/mnist/time\t0.088672876358\ttmp/mnist/train disc cost\t6.88723373413\n",
      "iter 2\ttmp/mnist/wasserstein distance\t1.82998526096\ttmp/mnist/train gen cost\t1.7570091486\ttmp/mnist/time\t0.0836329460144\ttmp/mnist/train disc cost\t3.19333791733\n",
      "iter 3\ttmp/mnist/wasserstein distance\t4.29297971725\ttmp/mnist/train gen cost\t3.76896905899\ttmp/mnist/time\t0.0795979499817\ttmp/mnist/train disc cost\t-2.68299078941\n",
      "iter 4\ttmp/mnist/wasserstein distance\t8.26098537445\ttmp/mnist/train gen cost\t6.49000120163\ttmp/mnist/time\t0.0789270401001\ttmp/mnist/train disc cost\t-7.91271018982\n",
      "iter 99\ttmp/mnist/wasserstein distance\t14.514799118\ttmp/mnist/train gen cost\t2.18128323555\ttmp/mnist/dev disc cost\t-14.514383316\ttmp/mnist/time\t0.0711939008612\ttmp/mnist/train disc cost\t-12.0795087814\n",
      "iter 199\ttmp/mnist/wasserstein distance\t12.6432218552\ttmp/mnist/train gen cost\t-1.34837782383\ttmp/mnist/dev disc cost\t-13.4402418137\ttmp/mnist/time\t0.0681299114227\ttmp/mnist/train disc cost\t-10.6004171371\n",
      "iter 299\ttmp/mnist/wasserstein distance\t12.5320911407\ttmp/mnist/train gen cost\t-0.100824400783\ttmp/mnist/dev disc cost\t-12.4962863922\ttmp/mnist/time\t0.0729612326622\ttmp/mnist/train disc cost\t-10.6265735626\n",
      "iter 399\ttmp/mnist/wasserstein distance\t12.404873848\ttmp/mnist/train gen cost\t0.457202941179\ttmp/mnist/dev disc cost\t-11.8662605286\ttmp/mnist/time\t0.0706792712212\ttmp/mnist/train disc cost\t-10.4374780655\n",
      "iter 499\ttmp/mnist/wasserstein distance\t11.4896144867\ttmp/mnist/train gen cost\t0.249365344644\ttmp/mnist/dev disc cost\t-9.41577339172\ttmp/mnist/time\t0.0730408644676\ttmp/mnist/train disc cost\t-9.73682594299\n",
      "iter 599\ttmp/mnist/wasserstein distance\t9.5256319046\ttmp/mnist/train gen cost\t0.416133284569\ttmp/mnist/dev disc cost\t-6.57604026794\ttmp/mnist/time\t0.0699599552155\ttmp/mnist/train disc cost\t-8.23618602753\n",
      "iter 699\ttmp/mnist/wasserstein distance\t8.52328491211\ttmp/mnist/train gen cost\t0.787253439426\ttmp/mnist/dev disc cost\t-5.96823549271\ttmp/mnist/time\t0.0741188883781\ttmp/mnist/train disc cost\t-7.3913025856\n",
      "iter 799\ttmp/mnist/wasserstein distance\t8.4474105835\ttmp/mnist/train gen cost\t1.0924962759\ttmp/mnist/dev disc cost\t-7.45517349243\ttmp/mnist/time\t0.0716662573814\ttmp/mnist/train disc cost\t-7.33158874512\n",
      "iter 899\ttmp/mnist/wasserstein distance\t8.03349018097\ttmp/mnist/train gen cost\t1.2530452013\ttmp/mnist/dev disc cost\t-4.52328300476\ttmp/mnist/time\t0.0740583920479\ttmp/mnist/train disc cost\t-6.98072862625\n",
      "iter 999\ttmp/mnist/wasserstein distance\t7.25178813934\ttmp/mnist/train gen cost\t0.827046871185\ttmp/mnist/dev disc cost\t-5.59916496277\ttmp/mnist/time\t0.0715844106674\ttmp/mnist/train disc cost\t-6.34707355499\n",
      "iter 1099\ttmp/mnist/wasserstein distance\t6.68826246262\ttmp/mnist/train gen cost\t0.055415019393\ttmp/mnist/dev disc cost\t-5.48369884491\ttmp/mnist/time\t0.0720580625534\ttmp/mnist/train disc cost\t-5.8754863739\n",
      "iter 1199\ttmp/mnist/wasserstein distance\t6.2686252594\ttmp/mnist/train gen cost\t-0.2670109272\ttmp/mnist/dev disc cost\t-6.74091148376\ttmp/mnist/time\t0.0723337483406\ttmp/mnist/train disc cost\t-5.50839710236\n",
      "iter 1299\ttmp/mnist/wasserstein distance\t6.01711082458\ttmp/mnist/train gen cost\t-0.227953180671\ttmp/mnist/dev disc cost\t-5.54602909088\ttmp/mnist/time\t0.0731108665466\ttmp/mnist/train disc cost\t-5.31578922272\n",
      "iter 1399\ttmp/mnist/wasserstein distance\t5.80834960938\ttmp/mnist/train gen cost\t-0.207384586334\ttmp/mnist/dev disc cost\t-5.8020324707\ttmp/mnist/time\t0.0710937213898\ttmp/mnist/train disc cost\t-5.13219118118\n",
      "iter 1499\ttmp/mnist/wasserstein distance\t5.62683534622\ttmp/mnist/train gen cost\t-0.100064471364\ttmp/mnist/dev disc cost\t-5.26879405975\ttmp/mnist/time\t0.0728928661346\ttmp/mnist/train disc cost\t-4.97457790375\n",
      "iter 1599\ttmp/mnist/wasserstein distance\t5.53232860565\ttmp/mnist/train gen cost\t0.0101368334144\ttmp/mnist/dev disc cost\t-5.22862958908\ttmp/mnist/time\t0.0700073671341\ttmp/mnist/train disc cost\t-4.88918161392\n",
      "iter 1699\ttmp/mnist/wasserstein distance\t5.39329957962\ttmp/mnist/train gen cost\t0.0467386469245\ttmp/mnist/dev disc cost\t-6.0580701828\ttmp/mnist/time\t0.073432328701\ttmp/mnist/train disc cost\t-4.79905080795\n",
      "iter 1799\ttmp/mnist/wasserstein distance\t5.2652759552\ttmp/mnist/train gen cost\t0.0775427669287\ttmp/mnist/dev disc cost\t-5.54755115509\ttmp/mnist/time\t0.0719275259972\ttmp/mnist/train disc cost\t-4.6822385788\n",
      "iter 1899\ttmp/mnist/wasserstein distance\t5.14301681519\ttmp/mnist/train gen cost\t0.19385689497\ttmp/mnist/dev disc cost\t-4.53097915649\ttmp/mnist/time\t0.073707613945\ttmp/mnist/train disc cost\t-4.56619882584\n",
      "iter 1999\ttmp/mnist/wasserstein distance\t5.06459569931\ttmp/mnist/train gen cost\t0.257622241974\ttmp/mnist/dev disc cost\t-4.31536054611\ttmp/mnist/time\t0.072233235836\ttmp/mnist/train disc cost\t-4.51343822479\n",
      "iter 2099\ttmp/mnist/wasserstein distance\t4.97207832336\ttmp/mnist/train gen cost\t0.164151132107\ttmp/mnist/dev disc cost\t-4.48688697815\ttmp/mnist/time\t0.0728193712234\ttmp/mnist/train disc cost\t-4.42113113403\n",
      "iter 2199\ttmp/mnist/wasserstein distance\t4.77152395248\ttmp/mnist/train gen cost\t0.251068562269\ttmp/mnist/dev disc cost\t-4.04015541077\ttmp/mnist/time\t0.0699907541275\ttmp/mnist/train disc cost\t-4.25606918335\n",
      "iter 2299\ttmp/mnist/wasserstein distance\t4.59559822083\ttmp/mnist/train gen cost\t0.294178664684\ttmp/mnist/dev disc cost\t-3.7383954525\ttmp/mnist/time\t0.0744263577461\ttmp/mnist/train disc cost\t-4.08026647568\n",
      "iter 2399\ttmp/mnist/wasserstein distance\t4.46887779236\ttmp/mnist/train gen cost\t0.376254886389\ttmp/mnist/dev disc cost\t-3.23313903809\ttmp/mnist/time\t0.0720866417885\ttmp/mnist/train disc cost\t-4.00043344498\n",
      "iter 2499\ttmp/mnist/wasserstein distance\t4.35602331161\ttmp/mnist/train gen cost\t0.365993231535\ttmp/mnist/dev disc cost\t-3.27553081512\ttmp/mnist/time\t0.0738970470428\ttmp/mnist/train disc cost\t-3.88169193268\n",
      "iter 2599\ttmp/mnist/wasserstein distance\t4.20675325394\ttmp/mnist/train gen cost\t0.495823353529\ttmp/mnist/dev disc cost\t-3.38228535652\ttmp/mnist/time\t0.0699084067345\ttmp/mnist/train disc cost\t-3.76830363274\n",
      "iter 2699\ttmp/mnist/wasserstein distance\t4.03357124329\ttmp/mnist/train gen cost\t0.631429791451\ttmp/mnist/dev disc cost\t-3.23861598969\ttmp/mnist/time\t0.0744192171097\ttmp/mnist/train disc cost\t-3.61328887939\n",
      "iter 2799\ttmp/mnist/wasserstein distance\t3.93447232246\ttmp/mnist/train gen cost\t0.664558410645\ttmp/mnist/dev disc cost\t-2.49051356316\ttmp/mnist/time\t0.0718533062935\ttmp/mnist/train disc cost\t-3.50717234612\n",
      "iter 2899\ttmp/mnist/wasserstein distance\t3.85942363739\ttmp/mnist/train gen cost\t0.739823698997\ttmp/mnist/dev disc cost\t-3.38409423828\ttmp/mnist/time\t0.070645134449\ttmp/mnist/train disc cost\t-3.45764183998\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-bf43d869b720>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0mfake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoisev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0minputv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfake\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m         \u001b[0mD_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0mD_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD_fake\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0mD_fake\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/m.nakhodnov/anaconda3/envs/py2.7.14/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-bf43d869b720>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mDIM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/m.nakhodnov/anaconda3/envs/py2.7.14/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/m.nakhodnov/anaconda3/envs/py2.7.14/lib/python2.7/site-packages/torch/nn/modules/container.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/m.nakhodnov/anaconda3/envs/py2.7.14/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhook_result\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/m.nakhodnov/anaconda3/envs/py2.7.14/lib/python2.7/collections.pyc\u001b[0m in \u001b[0;36mvalues\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;34m'od.values() -> list of values in od'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "import time\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn.datasets\n",
    "\n",
    "import tflib as lib\n",
    "import tflib.save_images\n",
    "import tflib.mnist\n",
    "import tflib.plot\n",
    "\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1)\n",
    "use_cuda = torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    gpu = 0\n",
    "\n",
    "DIM = 64 # Model dimensionality\n",
    "BATCH_SIZE = 50 # Batch size\n",
    "CRITIC_ITERS = 5 # For WGAN and WGAN-GP, number of critic iters per gen iter\n",
    "LAMBDA = 10 # Gradient penalty lambda hyperparameter\n",
    "ITERS = 200000 # How many generator iterations to train for\n",
    "OUTPUT_DIM = 784 # Number of pixels in MNIST (28*28)\n",
    "\n",
    "lib.print_model_settings(locals().copy())\n",
    "\n",
    "# ==================Definition Start======================\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        preprocess = nn.Sequential(\n",
    "            nn.Linear(128, 4*4*4*DIM),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "        block1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(4*DIM, 2*DIM, 5),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "        block2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(2*DIM, DIM, 5),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "        deconv_out = nn.ConvTranspose2d(DIM, 1, 8, stride=2)\n",
    "\n",
    "        self.block1 = block1\n",
    "        self.block2 = block2\n",
    "        self.deconv_out = deconv_out\n",
    "        self.preprocess = preprocess\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.preprocess(input)\n",
    "        output = output.view(-1, 4*DIM, 4, 4)\n",
    "        #print output.size()\n",
    "        output = self.block1(output)\n",
    "        #print output.size()\n",
    "        output = output[:, :, :7, :7]\n",
    "        #print output.size()\n",
    "        output = self.block2(output)\n",
    "        #print output.size()\n",
    "        output = self.deconv_out(output)\n",
    "        output = self.sigmoid(output)\n",
    "        #print output.size()\n",
    "        return output.view(-1, OUTPUT_DIM)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        main = nn.Sequential(\n",
    "            nn.Conv2d(1, DIM, 5, stride=2, padding=2),\n",
    "            # nn.Linear(OUTPUT_DIM, 4*4*4*DIM),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(DIM, 2*DIM, 5, stride=2, padding=2),\n",
    "            # nn.Linear(4*4*4*DIM, 4*4*4*DIM),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(2*DIM, 4*DIM, 5, stride=2, padding=2),\n",
    "            # nn.Linear(4*4*4*DIM, 4*4*4*DIM),\n",
    "            nn.ReLU(True),\n",
    "            # nn.Linear(4*4*4*DIM, 4*4*4*DIM),\n",
    "            # nn.LeakyReLU(True),\n",
    "            # nn.Linear(4*4*4*DIM, 4*4*4*DIM),\n",
    "            # nn.LeakyReLU(True),\n",
    "        )\n",
    "        self.main = main\n",
    "        self.output = nn.Linear(4*4*4*DIM, 1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        input = input.view(-1, 1, 28, 28)\n",
    "        out = self.main(input)\n",
    "        out = out.view(-1, 4*4*4*DIM)\n",
    "        out = self.output(out)\n",
    "        return out.view(-1)\n",
    "\n",
    "def generate_image(frame, netG):\n",
    "    noise = torch.randn(BATCH_SIZE, 128)\n",
    "    if use_cuda:\n",
    "        noise = noise.cuda(gpu)\n",
    "    noisev = autograd.Variable(noise, volatile=True)\n",
    "    samples = netG(noisev)\n",
    "    samples = samples.view(BATCH_SIZE, 28, 28)\n",
    "    # print samples.size()\n",
    "\n",
    "    samples = samples.cpu().data.numpy()\n",
    "\n",
    "    lib.save_images.save_images(\n",
    "        samples,\n",
    "        'tmp/mnist/samples_{}.png'.format(frame)\n",
    "    )\n",
    "\n",
    "# Dataset iterator\n",
    "train_gen, dev_gen, test_gen = lib.mnist.load(BATCH_SIZE, BATCH_SIZE)\n",
    "def inf_train_gen():\n",
    "    while True:\n",
    "        for images,targets in train_gen():\n",
    "            yield images\n",
    "\n",
    "def calc_gradient_penalty(netD, real_data, fake_data):\n",
    "    #print real_data.size()\n",
    "    alpha = torch.rand(BATCH_SIZE, 1)\n",
    "    alpha = alpha.expand(real_data.size())\n",
    "    alpha = alpha.cuda(gpu) if use_cuda else alpha\n",
    "\n",
    "    interpolates = alpha * real_data + ((1 - alpha) * fake_data)\n",
    "\n",
    "    if use_cuda:\n",
    "        interpolates = interpolates.cuda(gpu)\n",
    "    interpolates = autograd.Variable(interpolates, requires_grad=True)\n",
    "\n",
    "    disc_interpolates = netD(interpolates)\n",
    "\n",
    "    gradients = autograd.grad(outputs=disc_interpolates, inputs=interpolates,\n",
    "                              grad_outputs=torch.ones(disc_interpolates.size()).cuda(gpu) if use_cuda else torch.ones(\n",
    "                                  disc_interpolates.size()),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "\n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean() * LAMBDA\n",
    "    return gradient_penalty\n",
    "\n",
    "# ==================Definition End======================\n",
    "\n",
    "netG = Generator()\n",
    "netD = Discriminator()\n",
    "print(netG)\n",
    "print(netD)\n",
    "\n",
    "if use_cuda:\n",
    "    netD = netD.cuda(gpu)\n",
    "    netG = netG.cuda(gpu)\n",
    "\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=1e-4, betas=(0.5, 0.9))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=1e-4, betas=(0.5, 0.9))\n",
    "\n",
    "one = torch.FloatTensor([1])\n",
    "mone = one * -1\n",
    "if use_cuda:\n",
    "    one = one.cuda(gpu)\n",
    "    mone = mone.cuda(gpu)\n",
    "\n",
    "data = inf_train_gen()\n",
    "\n",
    "for iteration in xrange(ITERS):\n",
    "    start_time = time.time()\n",
    "    ############################\n",
    "    # (1) Update D network\n",
    "    ###########################\n",
    "    for p in netD.parameters():  # reset requires_grad\n",
    "        p.requires_grad = True  # they are set to False below in netG update\n",
    "\n",
    "    for iter_d in xrange(CRITIC_ITERS):\n",
    "        _data = data.next()\n",
    "        real_data = torch.Tensor(_data)\n",
    "        if use_cuda:\n",
    "            real_data = real_data.cuda(gpu)\n",
    "        real_data_v = autograd.Variable(real_data)\n",
    "\n",
    "        netD.zero_grad()\n",
    "\n",
    "        # train with real\n",
    "        D_real = netD(real_data_v)\n",
    "        D_real = D_real.mean()\n",
    "        # print D_real\n",
    "        D_real.backward(mone)\n",
    "\n",
    "        # train with fake\n",
    "        noise = torch.randn(BATCH_SIZE, 128)\n",
    "        if use_cuda:\n",
    "            noise = noise.cuda(gpu)\n",
    "        noisev = autograd.Variable(noise, volatile=True)  # totally freeze netG\n",
    "        fake = autograd.Variable(netG(noisev).data)\n",
    "        inputv = fake\n",
    "        D_fake = netD(inputv)\n",
    "        D_fake = D_fake.mean()\n",
    "        D_fake.backward(one)\n",
    "\n",
    "        # train with gradient penalty\n",
    "        gradient_penalty = calc_gradient_penalty(netD, real_data_v.data, fake.data)\n",
    "        gradient_penalty.backward()\n",
    "\n",
    "        D_cost = D_fake - D_real + gradient_penalty\n",
    "        Wasserstein_D = D_real - D_fake\n",
    "        optimizerD.step()\n",
    "\n",
    "    ############################\n",
    "    # (2) Update G network\n",
    "    ###########################\n",
    "    for p in netD.parameters():\n",
    "        p.requires_grad = False  # to avoid computation\n",
    "    netG.zero_grad()\n",
    "\n",
    "    noise = torch.randn(BATCH_SIZE, 128)\n",
    "    if use_cuda:\n",
    "        noise = noise.cuda(gpu)\n",
    "    noisev = autograd.Variable(noise)\n",
    "    fake = netG(noisev)\n",
    "    G = netD(fake)\n",
    "    G = G.mean()\n",
    "    G.backward(mone)\n",
    "    G_cost = -G\n",
    "    optimizerG.step()\n",
    "\n",
    "    # Write logs and save samples\n",
    "    lib.plot.plot('tmp/mnist/time', time.time() - start_time)\n",
    "    lib.plot.plot('tmp/mnist/train disc cost', D_cost.cpu().data.numpy())\n",
    "    lib.plot.plot('tmp/mnist/train gen cost', G_cost.cpu().data.numpy())\n",
    "    lib.plot.plot('tmp/mnist/wasserstein distance', Wasserstein_D.cpu().data.numpy())\n",
    "\n",
    "    # Calculate dev loss and generate samples every 100 iters\n",
    "    if iteration % 100 == 99:\n",
    "        dev_disc_costs = []\n",
    "        for images,_ in dev_gen():\n",
    "            imgs = torch.Tensor(images)\n",
    "            if use_cuda:\n",
    "                imgs = imgs.cuda(gpu)\n",
    "            imgs_v = autograd.Variable(imgs, volatile=True)\n",
    "\n",
    "            D = netD(imgs_v)\n",
    "            _dev_disc_cost = -D.mean().cpu().data.numpy()\n",
    "            dev_disc_costs.append(_dev_disc_cost)\n",
    "        lib.plot.plot('tmp/mnist/dev disc cost', np.mean(dev_disc_costs))\n",
    "\n",
    "        generate_image(iteration, netG)\n",
    "\n",
    "    # Write logs every 100 iters\n",
    "    if (iteration < 5) or (iteration % 100 == 99):\n",
    "        lib.plot.flush()\n",
    "\n",
    "    lib.plot.tick()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
